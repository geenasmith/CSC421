{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC421 Assignment 3 - Part II Naive Bayes Classification (5 points) #\n",
    "### Author: George Tzanetakis \n",
    "\n",
    "This notebook is based on the supporting material for topics covered in **Chapter 13 Quantifying Uncertainty**and **Chapter 20 - Statistical Learning Method** from the book *Artificial Intelligence: A Modern Approach.* This part does NOT rely on the provided code so you can complete it just using basic Python. \n",
    "\n",
    "```\n",
    "Misunderstanding of probability may be the greatest of all impediments\n",
    "to scientific literacy.\n",
    "\n",
    "Gould, Stephen Jay\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "\n",
    "Text categorization is the task of assigning a given document to one of a fixed set of categories, on the basis of text it contains. Naive Bayes models are often used for this task. In these models, the query variable is\n",
    "the document category, and the effect variables are the presence/absence\n",
    "of each word in the language; the assumption is that words occur independently in documents within a given category (condititional independence), with frequencies determined by document category. Download the following file: http://www.cs.cornell.edu/People/pabo/movie-review-data/review_polarity.tar.gz containing a dataset that has been used for text mining consisting of movie reviews classified into negative and positive. You\n",
    "will see that there are two folders for the positivie and negative category and they each contain multiple text files with the reviews. You can find more information about the dataset at: \n",
    "http://www.cs.cornell.edu/People/pabo/movie-review-data/\n",
    "\n",
    "\n",
    "Our goal will be to build a simple Naive Bayes classifier for this dataset. More complicated approaches using term frequency and inverse document frequency weighting and many more words are possible but the basic concepts\n",
    "are the same. The goal is to understand the whole process so DO NOT use existing machine learning packages but rather build the classifier from scratch.\n",
    "\n",
    "Our feature vector representation for each text file will be simply a binary vector that shows which of the following words are present in the text file: Awful Bad Boring Dull Effective Enjoyable Great Hilarious. For example the text file cv996 11592.txt would be represented as (0, 0, 0, 0, 1, 0, 1, 0) because it contains Effective and Great but none of the other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2A (Minimum) CSC421 -  (1 point, CSC581C - 0 points) \n",
    "\n",
    "Write code that parses the text files and calculates the probabilities for\n",
    "each dictionary word given the review polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of each word given a positive review: [0.019 0.255 0.048 0.023 0.12  0.095 0.408 0.125]\n",
      "Probability of each word given a negative review: [0.101 0.505 0.169 0.091 0.046 0.053 0.286 0.05 ]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE \n",
    "from os import listdir\n",
    "import numpy as np\n",
    "\n",
    "def parseFiles():\n",
    "    keyWords = [\"awful\", \"bad\",\"boring\",\"dull\",\"effective\",\"enjoyable\",\"great\",\"hilarious\"]\n",
    "    input_neg = \"./review_polarity/txt_sentoken/neg/\"\n",
    "    input_pos = \"./review_polarity/txt_sentoken/pos/\"\n",
    "    \n",
    "    neg_names = [(input_neg+f) for f in listdir(input_neg)]\n",
    "    pos_names = [(input_pos+f) for f in listdir(input_pos)]\n",
    "    \n",
    "    num_neg = len(neg_names)\n",
    "    num_pos = len(pos_names)\n",
    "    \n",
    "    neg_polarities = np.zeros((num_neg,len(keyWords)))\n",
    "    pos_polarities = np.zeros((num_pos,len(keyWords)))\n",
    "    \n",
    "    \n",
    "    for n in range(0,num_neg):\n",
    "        with open(neg_names[n],'r') as f:\n",
    "            words = f.read().split()\n",
    "            words = [w.lower() for w in words] # change every word to lowercase for easier parsing\n",
    "        neg_polarities[n,:] = [int(w in words) for w in keyWords]\n",
    "    \n",
    "    for n in range(0,num_pos):\n",
    "        with open(pos_names[n],'r') as f:\n",
    "            words = f.read().split()\n",
    "            words = [w.lower() for w in words] # change every word to lowercase for easier parsing\n",
    "        pos_polarities[n,:] = [int(w in words) for w in keyWords]\n",
    "    \n",
    "    \n",
    "    probGivenNeg = np.divide(np.sum(neg_polarities,0,int),num_neg)\n",
    "    probGivenPos = np.divide(np.sum(pos_polarities,0,int),num_pos)\n",
    "    \n",
    "    probPos = num_pos / (num_pos + num_neg)\n",
    "    probNeg = num_neg / (num_pos + num_neg)\n",
    "    \n",
    "    return probGivenNeg, probGivenPos, probNeg, probPos, neg_polarities, pos_polarities\n",
    "    \n",
    "\n",
    "probGivenNeg, probGivenPos, probNeg, probPos, neg_polarities, pos_polarities = parseFiles()\n",
    "print(\"Probability of each word given a positive review: \" + str(probGivenPos))\n",
    "print(\"Probability of each word given a negative review: \" + str(probGivenNeg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2B (Minimum) (CSC421 - 1 point, CSC581C - 0 point) \n",
    "\n",
    "\n",
    "Explain how the probability estimates for each dictionary word given the review polarity can be combined to form a Naive Bayes classifier. You can look up Bernoulli Bayes model for this simple model where only presence/absence of a word is modeled.\n",
    "\n",
    "Your answer should be a description of the process with equations and a specific example as markdown text NOT python code. You will write the code in the next questinon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "**\\# YOUR MARKDOWN TEXT GOES HERE**\n",
    "\n",
    "With Naive Bayes, we are assuming attributes are conditionally independent given the class value. As such, naive Bayes tells us  \n",
    "\n",
    "\\begin{align}\n",
    "P(c_1|e_1,e_2,...,e_n) = \\alpha P(e_1|c_1)...P(e_n|c_1)P(c_1)\n",
    "\\end{align}  \n",
    "\n",
    "Where $E=e_1,e_2,...,e_n$ are the instances, and $C=c_1,c_2,...,c_m$ are the classes.  \n",
    "\n",
    "In our case the classes are the types of reviews, ie. C={pos,neg}. The instances are the 8 dictionary words, ie. E={Awful, Bad, Boring, Dull, Effective, Enjoyable, Great, Hilarious}.  \n",
    "  \n",
    "If we have the probability estimates for each dictionary word given the review polarity, eg. P(Awful | pos), we can build a Naive Bayes classifier based on the information above.\n",
    "  \n",
    "We can calculate the probability of each word occuring given the polarity directly from our data, as well as the probability of being a positive or negative review. Using this, if we get a new review and want to classify if it is a positive or negative review, we can first determine if each word occurs or not, building our evidence. From this, we can use the following:  \n",
    "\\begin{align}\n",
    "&P(c|E) = P(c|e_1,e_2,...,e_n)\\\\\n",
    "&= P(c,e_1,e_2,...,e_n)\\\\\n",
    "&= P(e_1,e_2,...,e_n,c)\\\\\n",
    "&= aP(e_1|c)P(e_2|c)...P(e_n|c)P(c)\n",
    "\\end{align} \n",
    "  \n",
    "We would calculate this for $c=pos$ and $c=neg$, and the higher pribability indicates the polarity the review would be classified as. Note $\\alpha$ is just a normalization factor. We can calculate it to get a probability between [0,1] for each, however comparing the un-normalized probabilities directly will give the same classification answer.  \n",
    "  \n",
    "To give a concrete example, suppose the evidence for a review gives the following: $[Awful, Bad, Boring, Dull, Effective, Enjoyable, Great, Hilarious] = [1,1,0,1,0,0,0,1]$  \n",
    "\n",
    "We want to know if this review is positive or negative.  \n",
    "First, we will calculate $P(pos | e_1,e_2,...,e_8)$. This will give $P(pos | e_1,e_2,...,e_8) = \\alpha P(e_1|pos)P(e_2|pos)...P(e_8|pos)P(pos)$.  \n",
    "\n",
    "Next, we will calculate $P(neg | e_1,e_2,...,e_8)$. This will give $P(neg | e_1,e_2,...,e_8) = \\alpha P(e_1|neg)P(e_2|neg)...P(e_8|neg)P(neg)$.  \n",
    "\n",
    "In both cases, we will get a value multiplied by $\\alpha$ (we dont know $\\alpha$). If we want to get $\\alpha$, we add the 2 values. The class with the higher value will indicate the more probable classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2C (Expected) 1 point \n",
    "\n",
    "Write Python code for classifying a particular test instance (in our case movie review) following a Bernolli Bayes approach. Your code should calculate the likelihood the review is positive given the correspondng conditional probabilities for each dictionary word as well as the likelihood the review is negative given the corresponding conditional probabilities for each dictionary word. Check that your code works by providing a few example cases of prediction. Your code should be written from \"scratch\" and only use numpy/scipy but not machine learning libraries like scikit-learn or tensorflow. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review 1: neg\n",
      "review 2: pos\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE \n",
    "\n",
    "\"\"\"\n",
    "need to classify particular test instance following a bernolli bayes \n",
    "approach.\n",
    "\n",
    "-calculate \n",
    "(1) the likelihood the review is pos given the corresponding \n",
    "conditional probs for each dictionary word as well as \n",
    "(2) the likelihood the review is negative given the corresponding \n",
    "conditional probs for each dictionary word.\n",
    "- check that your code works by providing a few examples for prediction.\n",
    "\"\"\"\n",
    "\n",
    "def calcLikelihood(evidence, probGivenNeg, probGivenPos, probNeg, probPos):\n",
    "    \n",
    "    posLikelihood = 1\n",
    "    negLikelihood = 1\n",
    "    for n in range(0,len(evidence)):\n",
    "        if evidence[n] == 1:\n",
    "            posLikelihood *= probGivenPos[n]\n",
    "            negLikelihood *= probGivenNeg[n]\n",
    "        else:\n",
    "            posLikelihood *= (1-probGivenPos[n])\n",
    "            negLikelihood *= (1-probGivenNeg[n])\n",
    "    posLikelihood *= probPos\n",
    "    negLikelihood *= probNeg\n",
    "    \n",
    "    if posLikelihood > negLikelihood:\n",
    "        classifier = \"pos\"\n",
    "    elif negLikelihood > posLikelihood:\n",
    "        classifier = \"neg\"\n",
    "    else:\n",
    "        classifier = \"equal\"\n",
    "    \n",
    "    return classifier\n",
    "\n",
    "probGivenNeg, probGivenPos, probNeg, probPos, neg_polarities, pos_polarities = parseFiles()\n",
    "keyWords = [\"awful\", \"bad\",\"boring\",\"dull\",\"effective\",\"enjoyable\",\"great\",\"hilarious\"]\n",
    "\n",
    "review1 = \"this is an awful and boring movie.\"\n",
    "words = review1.split()\n",
    "evidence = [int(w in words) for w in keyWords]\n",
    "classifier = calcLikelihood(evidence, probGivenNeg, probGivenPos, probNeg, probPos)\n",
    "print(\"review 1: \" + classifier)\n",
    "\n",
    "review2 = \"enjoyable movie with great humour. was a bit dull at times however.\"\n",
    "words = review2.split()\n",
    "evidence = [int(w in words) for w in keyWords]\n",
    "classifier = calcLikelihood(evidence, probGivenNeg, probGivenPos, probNeg, probPos)\n",
    "print(\"review 2: \" + classifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 2D (Expected ) 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the classification accuracy and confusion matrix that you would obtain using the whole data set for both training and testing. Do not use machine learning libraries like scikit-learn or tensorflow for this only the basic numpy/scipy stuff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.674\n",
      "                |      Pos Review |      Neg Review\n",
      "----------------|-----------------|----------------\n",
      "      Pos Class |             756 |             408\n",
      "      Neg Class |             244 |             592\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "def calcClassificationAccuracy():\n",
    "    probGivenNeg, probGivenPos, probNeg, probPos, neg_polarities, pos_polarities = parseFiles()\n",
    "    keyWords = [\"awful\", \"bad\",\"boring\",\"dull\",\"effective\",\"enjoyable\",\"great\",\"hilarious\"]\n",
    "    \n",
    "#     loop through positive polarities and count correct/incorrect\n",
    "    correctPos = 0\n",
    "    incorrectPos = 0\n",
    "    correctNeg = 0\n",
    "    incorrectNeg = 0\n",
    "    for n in range(0,len(pos_polarities)):\n",
    "        classifier = calcLikelihood(pos_polarities[n,:], probGivenNeg, probGivenPos, probNeg, probPos)\n",
    "        if classifier == \"pos\":\n",
    "            correctPos += 1\n",
    "        else:\n",
    "            incorrectPos += 1\n",
    "\n",
    "#     loop through negative \n",
    "    for n in range(0,len(neg_polarities)):\n",
    "        classifier = calcLikelihood(neg_polarities[n,:], probGivenNeg, probGivenPos, probNeg, probPos)\n",
    "        if classifier == \"neg\":\n",
    "            correctNeg += 1\n",
    "        else:\n",
    "            incorrectNeg += 1\n",
    "            \n",
    "    accuracy = (correctPos + correctNeg) / (correctPos + incorrectPos + correctNeg + incorrectNeg)\n",
    "    \n",
    "    print(\"Accuracy: \" + str(accuracy))\n",
    "    \n",
    "    print(\"%15s | %15s | %15s\" % (\" \",\"Pos Review\", \"Neg Review\"))\n",
    "    print(\"----------------|-----------------|----------------\")\n",
    "    print(\"%15s | %15d | %15d\" % (\"Pos Class\",correctPos,incorrectNeg))\n",
    "    print(\"%15s | %15d | %15d\" % (\"Neg Class\",incorrectPos,correctNeg))\n",
    "\n",
    "calcClassificationAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 2E (Advanced) 1 point \n",
    "\n",
    "One can consider the Naive Bayes classifier a generative model that can generate binary feature vectors using the associated probabilities from the training data. The idea is similar to how we do direct sampling in\n",
    "Bayesian Networks and depends on generating random number from a discrete distribution. Describe how you would generate random movie reviews consisting solely of the words from the dictionary using your model. Show 5 examples of randomly generated positive reviews and 5 examples of randomly generated negative reviews. Each example should consists of a subset of the words in the dictionary. Hint: use probabilities to generate both the presence and absence of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive review #0: great bad\n",
      "Positive review #1: hilarious\n",
      "Positive review #2: hilarious\n",
      "Positive review #3: hilarious great\n",
      "Positive review #4: great\n",
      "\n",
      "Negative review #0: great effective enjoyable awful\n",
      "Negative review #1: dull bad\n",
      "Negative review #2: bad dull\n",
      "Negative review #3: bad\n",
      "Negative review #4: bad\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE \n",
    "\n",
    "\"\"\"\n",
    "Describe how you would generate random movie reviews consisting solely of the words \n",
    "from the dictionary using your model.\n",
    "\n",
    "Ans: \n",
    "From the previous calculations, we have probabilities of a keyword being present \n",
    "for both positive and negative reviews. To determine the subset of words in a randomly\n",
    "generated review, we can generate a random number between 0 and 1, and if the word is \n",
    "greater than the random number, we would add it to the sublist. If not, it would be absent.\n",
    "We can do this using the probability of a word occuring for a positive or negative review,\n",
    "depending on the type of review we want.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "def generateReview(reviewType):\n",
    "    probGivenNeg, probGivenPos, probNeg, probPos, neg_polarities, pos_polarities = parseFiles()\n",
    "    keyWords = [\"awful\", \"bad\",\"boring\",\"dull\",\"effective\",\"enjoyable\",\"great\",\"hilarious\"]\n",
    "    \n",
    "    rands = np.random.rand(len(keyWords))\n",
    "    \n",
    "    if reviewType == \"pos\":\n",
    "        words = [w for (i,w) in enumerate(keyWords) if probGivenPos[i]>rands[i]]\n",
    "    else:\n",
    "        words = [w for (i,w) in enumerate(keyWords) if probGivenNeg[i]>rands[i]]\n",
    "    random.shuffle(words)\n",
    "    return \" \".join(words)\n",
    "\n",
    "i = 0\n",
    "while i < 5:\n",
    "    review = generateReview(\"pos\")\n",
    "    if review == \"\":  # want sentences with at least 1 word\n",
    "        continue\n",
    "    print(\"Positive review #\" + str(i) + \": \" + str(review))\n",
    "    i += 1\n",
    "\n",
    "print()\n",
    "i = 0\n",
    "while i < 5:\n",
    "    review = generateReview(\"neg\")\n",
    "    if review == \"\":  # want sentences with at least 1 word\n",
    "        continue\n",
    "    print(\"Negative review #\" + str(i) + \": \" + str(review))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTION 2F (ADVANCED) (CSC421 - 0 points, CSC581C - 2 points)\n",
    "\n",
    "Check the associated README file and see what convention is used for the 10-fold cross-validation. Calculate the classification accuracy and confusion matrix using the recommended 10-fold cross-validation. Again do NOT use \n",
    "ML libraries such as scikit-learn or tensorflow and just use numpy/scipy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
